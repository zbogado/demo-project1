{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "EfficientNetB4_apple_Dataset",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'apple-disease-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2068739%2F3433042%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240520%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240520T053250Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D97a31eb280428300afa43107ae5474abb823e3adf6bc785577df1cc9fcc02e904f3fac3119cd258eb288383008afd0b859377981ea86573f3a1f20d4646f7dd91d5e7c7d7c73d26b5c186440eb9ea7a54bfc7e2a6ff9c20a824e9b18af9cfd567888ce256420c224f33c37e3258c6abad557be87e4193fb69ac9f1cfd22114fec5431b40710044be521c488bcf19e54e792aefefca62989c301405801e5579766f75237ef8edc7f98fd2e6f8f151c4d436d0d307cf17bb81f54c59fdd8e049761a30a8c15e0fa98d6a59339486e5223552ca47b89d34f82e27e84d68852d84da5a6c7822b6e97b1079a207bb7a40b1aeb10001a2193d24344379ee9eeeebb9a5,d-kap:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2464177%2F4176149%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240520%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240520T053250Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D4794d7ab24dfc6269fd66e3e2aee238233ec75e06088b76f08b14c5c42f3d82ae473e060716f36d633467990ce2b12effa2ecb62a81edb7e871b358528ebfddb77b25809a915b024120b8e79d74e34204ef69f93e5321e6cccdefb0cca1c2d139e819675aa88e8e0a141f39f10aafbffe950e56d04a5ad5a60c2b9276662a22432f28c3b6da2c817f70edf8589db5227005d892d32c7ccae05522ad7ed274b785cf1997b3dcb864e0bc892a2e6df074c54e5e6c591ee9556aa19b0af5102ddeba9de638aba96bccb3a4b58c8e311a10bbb88c1a3ec4052820351dfb89af06fa913c1b928188b6fb7f13bdedac407e1b0fad8e65b199a0f4050c7df81a2939d80,tuner-model:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F3180412%2F5514664%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240520%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240520T053250Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D07844259d9bf48eaf9f0ec42df6bd212bad7fe92867b5be1c389c92d91cfc0262b360eb34b4189be56bf39c52aec75976c5e6e1dfabda7aad22fee04e9ecbb1b8e16cc078e635e304917f30038d51c552e1ac3e9ef5424e8c3f5dd6da90a381aeda5eab901d6e4977bda134e8bfb59443a2b29adcbfb78271e78b84a2838f545199d45e7a98ef24186dd5748cb8679ea0f926b1e6a196c9cf317d24e6156e07fe5bc97647a57be9f21fe6dfa7f8648cdd45944ae4bc8a57797b916039f376f130fa3fb516e94c1ce3f9afdf5f52b2adbd2a332e4b6bb8cdec0bc846304856b75d4dcebbb1dd5020cb1e770bef1d983e0756fc9b2852257f39608923d84ab3fbc'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "xsIZ3MInfS_u"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2023-04-25T03:21:18.553762Z",
          "iopub.execute_input": "2023-04-25T03:21:18.554699Z",
          "iopub.status.idle": "2023-04-25T03:21:22.405316Z",
          "shell.execute_reply.started": "2023-04-25T03:21:18.554644Z",
          "shell.execute_reply": "2023-04-25T03:21:22.40433Z"
        },
        "trusted": true,
        "id": "SsUGAD9lfS_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Set the source directory\n",
        "src_dir = \"/kaggle/input/apple-disease-dataset/datasets/train\"\n",
        "\n",
        "# Set the destination directory\n",
        "dst_dir = \"/kaggle/working/apple-disease-dataset/datasets/train\"\n",
        "\n",
        "# Remove the destination directory if it already exists\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "\n",
        "# Copy the contents of the source directory to the destination directory\n",
        "shutil.copytree(src_dir, dst_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:21:53.118918Z",
          "iopub.execute_input": "2023-04-25T03:21:53.11955Z",
          "iopub.status.idle": "2023-04-25T03:22:13.820675Z",
          "shell.execute_reply.started": "2023-04-25T03:21:53.119509Z",
          "shell.execute_reply": "2023-04-25T03:22:13.819505Z"
        },
        "trusted": true,
        "id": "hUuLXge4fS_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Set the source directory\n",
        "src_dir = \"/kaggle/input/apple-disease-dataset/datasets/test\"\n",
        "\n",
        "# Set the destination directory\n",
        "dst_dir = \"/kaggle/working/apple-disease-dataset/datasets/test\"\n",
        "\n",
        "# Remove the destination directory if it already exists\n",
        "if os.path.exists(dst_dir):\n",
        "    shutil.rmtree(dst_dir)\n",
        "\n",
        "# Copy the contents of the source directory to the destination directory\n",
        "shutil.copytree(src_dir, dst_dir)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:22:29.567039Z",
          "iopub.execute_input": "2023-04-25T03:22:29.567662Z",
          "iopub.status.idle": "2023-04-25T03:22:34.873354Z",
          "shell.execute_reply.started": "2023-04-25T03:22:29.567623Z",
          "shell.execute_reply": "2023-04-25T03:22:34.872214Z"
        },
        "trusted": true,
        "id": "ZbdCGzyKfS_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths to source directory and two destination directories\n",
        "src_dir = r'/kaggle/input/d-kap/APPLE_DISEASE_DATASET/APPLE ROT LEAVES'\n",
        "dst_dir_1 = '/kaggle/working/apple-disease-dataset/datasets/train/black_rot'\n",
        "dst_dir_2 = '/kaggle/working/apple-disease-dataset/datasets/test/black_rot'\n",
        "\n",
        "# Create the destination directories if they don't already exist\n",
        "if not os.path.exists(dst_dir_1):\n",
        "    os.makedirs(dst_dir_1)\n",
        "if not os.path.exists(dst_dir_2):\n",
        "    os.makedirs(dst_dir_2)\n",
        "\n",
        "# Get a list of all files in the source directory\n",
        "files = os.listdir(src_dir)\n",
        "\n",
        "# Calculate the number of files to copy to each destination directory (60% and 40%)\n",
        "num_files_to_copy_1 = int(len(files) * 0.6)\n",
        "num_files_to_copy_2 = len(files) - num_files_to_copy_1\n",
        "\n",
        "# Randomly select the files to copy to each destination directory\n",
        "files_to_copy_1 = random.sample(files, num_files_to_copy_1)\n",
        "files_to_copy_2 = list(set(files) - set(files_to_copy_1))\n",
        "\n",
        "# Copy the selected files to each destination directory\n",
        "for file_name in files_to_copy_1:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_1, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)\n",
        "\n",
        "for file_name in files_to_copy_2:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_2, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:22:37.622505Z",
          "iopub.execute_input": "2023-04-25T03:22:37.622879Z",
          "iopub.status.idle": "2023-04-25T03:22:37.95948Z",
          "shell.execute_reply.started": "2023-04-25T03:22:37.622847Z",
          "shell.execute_reply": "2023-04-25T03:22:37.958481Z"
        },
        "trusted": true,
        "id": "HlLc_PdQfS_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths to source directory and two destination directories\n",
        "src_dir = r'/kaggle/input/d-kap/APPLE_DISEASE_DATASET/HEALTHY LEAVES'\n",
        "dst_dir_1 = '/kaggle/working/apple-disease-dataset/datasets/train/healthy'\n",
        "dst_dir_2 = '/kaggle/working/apple-disease-dataset/datasets/test/healthy'\n",
        "\n",
        "# Create the destination directories if they don't already exist\n",
        "if not os.path.exists(dst_dir_1):\n",
        "    os.makedirs(dst_dir_1)\n",
        "if not os.path.exists(dst_dir_2):\n",
        "    os.makedirs(dst_dir_2)\n",
        "\n",
        "# Get a list of all files in the source directory\n",
        "files = os.listdir(src_dir)\n",
        "\n",
        "# Calculate the number of files to copy to each destination directory (60% and 40%)\n",
        "num_files_to_copy_1 = int(len(files) * 0.6)\n",
        "num_files_to_copy_2 = len(files) - num_files_to_copy_1\n",
        "\n",
        "# Randomly select the files to copy to each destination directory\n",
        "files_to_copy_1 = random.sample(files, num_files_to_copy_1)\n",
        "files_to_copy_2 = list(set(files) - set(files_to_copy_1))\n",
        "\n",
        "# Copy the selected files to each destination directory\n",
        "for file_name in files_to_copy_1:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_1, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)\n",
        "\n",
        "for file_name in files_to_copy_2:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_2, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:22:42.662791Z",
          "iopub.execute_input": "2023-04-25T03:22:42.663726Z",
          "iopub.status.idle": "2023-04-25T03:22:42.84438Z",
          "shell.execute_reply.started": "2023-04-25T03:22:42.663671Z",
          "shell.execute_reply": "2023-04-25T03:22:42.843166Z"
        },
        "trusted": true,
        "id": "mIyJ0iewfS_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths to source directory and two destination directories\n",
        "src_dir = r'/kaggle/input/d-kap/APPLE_DISEASE_DATASET/LEAF BLOTCH'\n",
        "dst_dir_1 = '/kaggle/working/apple-disease-dataset/datasets/train/cedar_apple_rust'\n",
        "dst_dir_2 = '/kaggle/working/apple-disease-dataset/datasets/test/cedar_apple_rust'\n",
        "\n",
        "# Create the destination directories if they don't already exist\n",
        "if not os.path.exists(dst_dir_1):\n",
        "    os.makedirs(dst_dir_1)\n",
        "if not os.path.exists(dst_dir_2):\n",
        "    os.makedirs(dst_dir_2)\n",
        "\n",
        "# Get a list of all files in the source directory\n",
        "files = os.listdir(src_dir)\n",
        "\n",
        "# Calculate the number of files to copy to each destination directory (60% and 40%)\n",
        "num_files_to_copy_1 = int(len(files) * 0.6)\n",
        "num_files_to_copy_2 = len(files) - num_files_to_copy_1\n",
        "\n",
        "# Randomly select the files to copy to each destination directory\n",
        "files_to_copy_1 = random.sample(files, num_files_to_copy_1)\n",
        "files_to_copy_2 = list(set(files) - set(files_to_copy_1))\n",
        "\n",
        "# Copy the selected files to each destination directory\n",
        "for file_name in files_to_copy_1:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_1, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)\n",
        "\n",
        "for file_name in files_to_copy_2:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_2, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:23:08.534769Z",
          "iopub.execute_input": "2023-04-25T03:23:08.535363Z",
          "iopub.status.idle": "2023-04-25T03:23:08.972018Z",
          "shell.execute_reply.started": "2023-04-25T03:23:08.535324Z",
          "shell.execute_reply": "2023-04-25T03:23:08.970011Z"
        },
        "trusted": true,
        "id": "gEdXvtdsfS_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths to source directory and two destination directories\n",
        "src_dir = r'/kaggle/input/d-kap/APPLE_DISEASE_DATASET/SCAB LEAVES'\n",
        "dst_dir_1 = '/kaggle/working/apple-disease-dataset/datasets/train/apple_scab'\n",
        "dst_dir_2 = '/kaggle/working/apple-disease-dataset/datasets/test/apple_scab'\n",
        "\n",
        "# Create the destination directories if they don't already exist\n",
        "if not os.path.exists(dst_dir_1):\n",
        "    os.makedirs(dst_dir_1)\n",
        "if not os.path.exists(dst_dir_2):\n",
        "    os.makedirs(dst_dir_2)\n",
        "\n",
        "# Get a list of all files in the source directory\n",
        "files = os.listdir(src_dir)\n",
        "\n",
        "# Calculate the number of files to copy to each destination directory (60% and 40%)\n",
        "num_files_to_copy_1 = int(len(files) * 0.6)\n",
        "num_files_to_copy_2 = len(files) - num_files_to_copy_1\n",
        "\n",
        "# Randomly select the files to copy to each destination directory\n",
        "files_to_copy_1 = random.sample(files, num_files_to_copy_1)\n",
        "files_to_copy_2 = list(set(files) - set(files_to_copy_1))\n",
        "\n",
        "# Copy the selected files to each destination directory\n",
        "for file_name in files_to_copy_1:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_1, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)\n",
        "\n",
        "for file_name in files_to_copy_2:\n",
        "    src_file_path = os.path.join(src_dir, file_name)\n",
        "    dst_file_path = os.path.join(dst_dir_2, file_name)\n",
        "    shutil.copy(src_file_path, dst_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:23:14.168302Z",
          "iopub.execute_input": "2023-04-25T03:23:14.169002Z",
          "iopub.status.idle": "2023-04-25T03:23:14.731466Z",
          "shell.execute_reply.started": "2023-04-25T03:23:14.168961Z",
          "shell.execute_reply": "2023-04-25T03:23:14.730468Z"
        },
        "trusted": true,
        "id": "wdwvd_4HfS_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:23:18.231175Z",
          "iopub.execute_input": "2023-04-25T03:23:18.231574Z",
          "iopub.status.idle": "2023-04-25T03:23:29.272312Z",
          "shell.execute_reply.started": "2023-04-25T03:23:18.231541Z",
          "shell.execute_reply": "2023-04-25T03:23:29.270945Z"
        },
        "trusted": true,
        "id": "IyDO-Z4xfS_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.9"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:23:29.274722Z",
          "iopub.execute_input": "2023-04-25T03:23:29.275941Z",
          "iopub.status.idle": "2023-04-25T03:24:37.562477Z",
          "shell.execute_reply.started": "2023-04-25T03:23:29.275895Z",
          "shell.execute_reply": "2023-04-25T03:24:37.56128Z"
        },
        "trusted": true,
        "id": "992ijNIOfS_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "def build_model(hp):\n",
        "    base_model = EfficientNetB4(\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        input_shape=(224, 224, 3),\n",
        "        pooling=\"avg\",\n",
        "    )\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Sequential([base_model])\n",
        "\n",
        "    model.add(Dense(hp.Int(f\"dense_units_1\", 128, 512, 64), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "    model.add(Dropout(hp.Float(f\"dropout_1\", 0.2, 0.5, 0.1)))\n",
        "\n",
        "    model.add(Dense(hp.Int(f\"dense_units_2\", 64, 256, 32), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "    model.add(Dropout(hp.Float(f\"dropout_2\", 0.2, 0.5, 0.1)))\n",
        "\n",
        "    model.add(Dense(hp.Int(f\"dense_units_3\", 32, 128, 16), activation=\"relu\", kernel_regularizer=regularizers.l2(0.001)))\n",
        "    model.add(Dropout(hp.Float(f\"dropout_3\", 0.2, 0.5, 0.1)))\n",
        "\n",
        "    model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "    opt = Adam(learning_rate=hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\"))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define image data generator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Load the dataset\n",
        "train_data = datagen.flow_from_directory('/kaggle/working/apple-disease-dataset/datasets/train', target_size=(224,224), batch_size=32, class_mode='categorical')\n",
        "val_data = datagen.flow_from_directory('/kaggle/working/apple-disease-dataset/datasets/test', target_size=(224,224), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    directory='/kaggle/working/',\n",
        "    project_name='apple_leaves')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:24:50.561839Z",
          "iopub.execute_input": "2023-04-25T03:24:50.562225Z",
          "iopub.status.idle": "2023-04-25T03:25:06.208769Z",
          "shell.execute_reply.started": "2023-04-25T03:24:50.562186Z",
          "shell.execute_reply": "2023-04-25T03:25:06.207619Z"
        },
        "trusted": true,
        "id": "MTgzgPW2fS_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_data, epochs=7, validation_data=val_data)\n",
        "\n",
        "# Fit the model with the best hyperparameters\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "best_model.save('tuner_best_model_EfficientNetB4.h5')"
      ],
      "metadata": {
        "id": "xf_d1WDjfS_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "best_model = tf.keras.models.load_model('/kaggle/input/tuner-model/tuner_best_model_EfficientNetB4.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:30:05.327227Z",
          "iopub.execute_input": "2023-04-25T03:30:05.327921Z",
          "iopub.status.idle": "2023-04-25T03:30:11.726985Z",
          "shell.execute_reply.started": "2023-04-25T03:30:05.327881Z",
          "shell.execute_reply": "2023-04-25T03:30:11.725851Z"
        },
        "trusted": true,
        "id": "hlufGTqafS_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(train_data, epochs=100, validation_data=val_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T03:30:20.537706Z",
          "iopub.execute_input": "2023-04-25T03:30:20.538087Z",
          "iopub.status.idle": "2023-04-25T07:02:31.425482Z",
          "shell.execute_reply.started": "2023-04-25T03:30:20.538054Z",
          "shell.execute_reply": "2023-04-25T07:02:31.42448Z"
        },
        "trusted": true,
        "id": "iWjdiyAtfS_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.save(\"final_model_efficientnet.h5\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:02:31.427463Z",
          "iopub.execute_input": "2023-04-25T07:02:31.42811Z",
          "iopub.status.idle": "2023-04-25T07:02:32.117785Z",
          "shell.execute_reply.started": "2023-04-25T07:02:31.428069Z",
          "shell.execute_reply": "2023-04-25T07:02:32.116708Z"
        },
        "trusted": true,
        "id": "i8OFpvyYfS_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:02:32.119688Z",
          "iopub.execute_input": "2023-04-25T07:02:32.120063Z",
          "iopub.status.idle": "2023-04-25T07:02:32.176326Z",
          "shell.execute_reply.started": "2023-04-25T07:02:32.120025Z",
          "shell.execute_reply": "2023-04-25T07:02:32.175246Z"
        },
        "trusted": true,
        "id": "CSCjrHtVfS_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:02:32.178972Z",
          "iopub.execute_input": "2023-04-25T07:02:32.180074Z",
          "iopub.status.idle": "2023-04-25T07:02:43.418297Z",
          "shell.execute_reply.started": "2023-04-25T07:02:32.180033Z",
          "shell.execute_reply": "2023-04-25T07:02:43.416715Z"
        },
        "trusted": true,
        "id": "0GuPZs0MfS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "# Generate a diagram of the model structure and save it as an image file\n",
        "plot_model(best_model, to_file='model.png', show_shapes=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:02:43.420473Z",
          "iopub.execute_input": "2023-04-25T07:02:43.420894Z",
          "iopub.status.idle": "2023-04-25T07:02:43.617085Z",
          "shell.execute_reply.started": "2023-04-25T07:02:43.420848Z",
          "shell.execute_reply": "2023-04-25T07:02:43.615404Z"
        },
        "trusted": true,
        "id": "SfjojIZOfS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = best_model.evaluate(train_data)\n",
        "val_loss, val_acc = best_model.evaluate(val_data)\n",
        "\n",
        "print(f\"Final training accuracy: {train_acc:.4f}\")\n",
        "print(f\"Final validation accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:13:55.220838Z",
          "iopub.execute_input": "2023-04-25T07:13:55.221242Z",
          "iopub.status.idle": "2023-04-25T07:16:02.829303Z",
          "shell.execute_reply.started": "2023-04-25T07:13:55.221207Z",
          "shell.execute_reply": "2023-04-25T07:16:02.828303Z"
        },
        "trusted": true,
        "id": "M-MEf1fbfS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.load_model('/kaggle/working/final_model_efficientnet.h5')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:41:40.71331Z",
          "iopub.execute_input": "2023-04-25T07:41:40.714067Z",
          "iopub.status.idle": "2023-04-25T07:41:45.927476Z",
          "shell.execute_reply.started": "2023-04-25T07:41:40.714023Z",
          "shell.execute_reply": "2023-04-25T07:41:45.926411Z"
        },
        "trusted": true,
        "id": "oUEz2d_5fS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(train_data)\n",
        "val_loss, val_acc = model.evaluate(val_data)\n",
        "# Print the validation loss and accuracy\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-04-25T07:41:45.929908Z",
          "iopub.execute_input": "2023-04-25T07:41:45.930296Z",
          "iopub.status.idle": "2023-04-25T07:44:52.536215Z",
          "shell.execute_reply.started": "2023-04-25T07:41:45.930258Z",
          "shell.execute_reply": "2023-04-25T07:44:52.535139Z"
        },
        "trusted": true,
        "id": "XXeuyrCxfS_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eriMdJAhfS_6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}